{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Import necessary libraries\n",
    "# -------------------------------\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Local module\n",
    "from psrt import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "encoder = 'PSRT'\n",
    "\n",
    "csv_names = [\n",
    "    'Yau2020_record_processed',\n",
    "    # 'Yau2022_record_processed',\n",
    "    # 'NCBI_record_valid_nucleotide',\n",
    "    # 'NCBI_record_valid_count',\n",
    "]\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Stacking\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def stack_arrays_vertically(file_paths):\n",
    "    \"\"\"\n",
    "    Load NumPy arrays from given file paths and stack them vertically.\n",
    "\n",
    "    Parameters:\n",
    "        file_paths (list of str): List of file paths to the NumPy arrays.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A single vertically stacked NumPy array.\n",
    "    \"\"\"\n",
    "    # Load each array and store it in a list\n",
    "    # arrays = [np.load(path) for path in file_paths]\n",
    "    arrays = [np.load(path).reshape(-1) for path in file_paths]\n",
    "    \n",
    "    # Stack the arrays vertically\n",
    "    stacked_array = np.vstack(arrays)\n",
    "    \n",
    "    return stacked_array\n",
    "\n",
    "\n",
    "# encoder = 'PSRT'\n",
    "\n",
    "features_needed = [('betti', 2), ('f', 2), ('facet', 2), ('h', 3)]\n",
    "\n",
    "\n",
    "for data_name in csv_names:\n",
    "    print(data_name)\n",
    "    for k in range(k_chosen,k_chosen+1):\n",
    "        print(k)\n",
    "        path_to_features = f'features/{encoder}/{data_name}/{k}'\n",
    "        path_to_data = f'data/{data_name}'\n",
    "\n",
    "        # Read CSV file into DataFrame\n",
    "        df = pd.read_csv(f\"{path_to_data}.csv\")\n",
    "        # Load and sort accession IDs from metadata\n",
    "        accessions = sorted(df['Accession (version)'].to_list())\n",
    "\n",
    "        # Path to folder with feature files\n",
    "        folder_path = path_to_features\n",
    "\n",
    "        for considered_feature, considered_max_dimension in features_needed:\n",
    "            print(considered_feature, considered_max_dimension)\n",
    "            for d in range(considered_max_dimension+1):\n",
    "                print(\"d \", d)\n",
    "\n",
    "                # List all betti0 .npy files\n",
    "                file_names = [\n",
    "                    f for f in os.listdir(folder_path)\n",
    "                    if f.endswith('.npy') and f'{considered_feature}{d}' in f and os.path.isfile(os.path.join(folder_path, f))\n",
    "                ]\n",
    "\n",
    "                # Extract accession IDs from filenames (assumes format: accession_betti0.npy)\n",
    "                modified_names = [f.rsplit(f'_{considered_feature}{d}', 1)[0] for f in file_names]\n",
    "\n",
    "                # Filter accession IDs that have corresponding feature files\n",
    "                matched_accessions = [acc for acc in accessions if acc in modified_names]\n",
    "                print(\"accessions \", len(accessions))\n",
    "                print(\"matched\" , len(matched_accessions))\n",
    "\n",
    "                # Map accession â†’ index in file_names\n",
    "                element_to_index = {name: idx for idx, name in enumerate(modified_names)}\n",
    "\n",
    "                # Build index list (skip any accessions not found in file_names)\n",
    "                indices = [element_to_index[acc] for acc in matched_accessions if acc in element_to_index]\n",
    "\n",
    "                # Sort file names to match accession order\n",
    "                file_names_sorted = [file_names[i] for i in indices]\n",
    "\n",
    "                # Full paths to sorted .npy files\n",
    "                file_paths = [os.path.join(folder_path, fname) for fname in file_names_sorted]\n",
    "\n",
    "                np.save(f'features/{encoder}/{data_name}/k{k}_{considered_feature}{d}.npy', stack_arrays_vertically(file_paths))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Import necessary libraries\n",
    "# -------------------------------\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Local module\n",
    "from psrt import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Featurization\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "encoder = 'PSRT'\n",
    "max_dimension = 2\n",
    "num = 2\n",
    "k_chosen = 4\n",
    "\n",
    "csv_names = [\n",
    "    'Yau2020_record_processed',\n",
    "    # 'Yau2022_record_processed',\n",
    "    # 'NCBI_record_valid_nucleotide',\n",
    "    # 'NCBI_record_valid_count',\n",
    "]\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Configuration parameters\n",
    "# -------------------------------\n",
    "# encoder = 'PSRT'\n",
    "# max_dimension = 2\n",
    "alphabet = [\"A\", \"C\", \"G\", \"T\"]\n",
    "# num = 0\n",
    "\n",
    "# List of dataset base names (CSV and FASTA share the same prefix)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Loop over datasets\n",
    "# -------------------------------\n",
    "for data_name in csv_names:\n",
    "    print(data_name)\n",
    "    path_to_data = f\"./data/{data_name}\"\n",
    "\n",
    "    # Loop over k-mer sizes from 1 to 7\n",
    "    for k in range(k_chosen, k_chosen+1):\n",
    "        print(k)\n",
    "\n",
    "        # Load accessions from CSV\n",
    "        df = pd.read_csv(f\"{path_to_data}.csv\")\n",
    "        x = df['Accession (version)'].to_list()\n",
    "\n",
    "        # Parse FASTA sequences into a list of SeqRecord objects\n",
    "        file_path = f'{path_to_data}.fasta'\n",
    "        DNAs = list(SeqIO.parse(file_path, \"fasta\"))\n",
    "\n",
    "        # Create a dictionary: accession → SeqRecord\n",
    "        dna_dict = {record.id: record for record in DNAs}\n",
    "\n",
    "        # Match sequences with accessions from CSV, preserving order\n",
    "        ordered_dnas = [dna_dict[accession] for accession in x if accession in dna_dict]\n",
    "        dna_list = [str(record.seq) for record in ordered_dnas]\n",
    "\n",
    "        # Generate all possible k-mers of length k\n",
    "        kmers = generate_all_kmers(alphabet, k)\n",
    "\n",
    "        # Define filtration values (uniform grid scaled by 4^k)\n",
    "        specific_filtration = np.array([i * 4**k for i in range(0, num + 1)])\n",
    "\n",
    "        # -------------------------------\n",
    "        # Process each DNA sequence\n",
    "        # -------------------------------\n",
    "        # for i in range(len(dna_list)):\n",
    "        for i in range(len(dna_list)):\n",
    "            print(\"sample \", i)\n",
    "            print(\"accession \", ordered_dnas[i].id)\n",
    "            dna = dna_list[i]  # ← fix: define current sequence\n",
    "\n",
    "            # Initialize per-dimension feature accumulators\n",
    "            betti_result = (max_dimension + 1) * [None]\n",
    "            f_result = (max_dimension + 1) * [None]\n",
    "            h_result = (max_dimension + 2) * [None]\n",
    "            facet_result = (max_dimension + 1) * [None]\n",
    "\n",
    "            # -------------------------------\n",
    "            # Loop over all possible k-mers\n",
    "            # -------------------------------\n",
    "            for kmer in kmers:\n",
    "                points = occurrence(dna, kmer)\n",
    "\n",
    "                # Handle case where k-mer is absent\n",
    "                if len(points) == 0:\n",
    "                    zero_curve = np.array((1 + num) * [0])\n",
    "                    betti_curves = (max_dimension + 1) * [zero_curve]\n",
    "                    f_curves = (max_dimension + 1) * [zero_curve]\n",
    "                    h_curves = (max_dimension + 2) * [zero_curve]\n",
    "                    facet_curves = (max_dimension + 1) * [zero_curve]\n",
    "\n",
    "                    # Append zero curves to result arrays\n",
    "                    for d in range(max_dimension + 1):\n",
    "                        if betti_result[d] is None:\n",
    "                            betti_result[d] = betti_curves[d]\n",
    "                        else:\n",
    "                            betti_result[d] = np.vstack([betti_result[d], betti_curves[d]])\n",
    "\n",
    "                        if f_result[d] is None:\n",
    "                            f_result[d] = f_curves[d]\n",
    "                        else:\n",
    "                            f_result[d] = np.vstack([f_result[d], f_curves[d]])\n",
    "\n",
    "                        if facet_result[d] is None:\n",
    "                            facet_result[d] = facet_curves[d]\n",
    "                        else:\n",
    "                            facet_result[d] = np.vstack([facet_result[d], facet_curves[d]])\n",
    "\n",
    "                    # Append zero curves to result arrays\n",
    "                    for d in range(max_dimension + 2):\n",
    "                        if h_result[d] is None:\n",
    "                            h_result[d] = h_curves[d]\n",
    "                        else:\n",
    "                            h_result[d] = np.vstack([h_result[d], h_curves[d]])\n",
    "                    continue\n",
    "\n",
    "                # -------------------------------\n",
    "                # Compute PH features for current k-mer\n",
    "                # -------------------------------\n",
    "                points = np.array(points)[:, np.newaxis]  # Reshape to 2D\n",
    "\n",
    "                ph = PH(\n",
    "                    points,\n",
    "                    max_dimension=max_dimension,\n",
    "                    max_edge_length=2.0,\n",
    "                    specific_filtration=specific_filtration\n",
    "                )\n",
    "\n",
    "                alphas, betti_curves = ph.betti_curves()\n",
    "                f_curves = ph.compute_f_vector_curves()\n",
    "                h_curves = ph.compute_h_vector_curves()\n",
    "                facet_curves = ph.facet_curves()\n",
    "\n",
    "                # Stack curves per dimension\n",
    "                for d in range(max_dimension + 1):\n",
    "                    if betti_result[d] is None:\n",
    "                        betti_result[d] = betti_curves.get(d, np.zeros_like(alphas))\n",
    "                    else:\n",
    "                        betti_result[d] = np.vstack([betti_result[d], betti_curves.get(d, np.zeros_like(alphas))])\n",
    "\n",
    "                    if f_result[d] is None:\n",
    "                        f_result[d] = f_curves.get(d, np.zeros_like(alphas))\n",
    "                    else:\n",
    "                        f_result[d] = np.vstack([f_result[d], f_curves.get(d, np.zeros_like(alphas))])\n",
    "\n",
    "                    if facet_result[d] is None:\n",
    "                        facet_result[d] = facet_curves.get(d, np.zeros_like(alphas))\n",
    "                    else:\n",
    "                        facet_result[d] = np.vstack([facet_result[d], facet_curves.get(d, np.zeros_like(alphas))])\n",
    "\n",
    "                # Stack curves per dimension\n",
    "                for d in range(max_dimension + 2):\n",
    "                    if h_result[d] is None:\n",
    "                        h_result[d] = h_curves.get(d, np.zeros_like(alphas))\n",
    "                    else:\n",
    "                        h_result[d] = np.vstack([h_result[d], h_curves.get(d, np.zeros_like(alphas))])\n",
    "\n",
    "            # -------------------------------\n",
    "            # Save results to .npy files\n",
    "            # -------------------------------\n",
    "            save_path = f\"features/{encoder}/{data_name}/{k}\"\n",
    "            os.makedirs(save_path, exist_ok=True)   # create folder path if missing\n",
    "            for d in range(max_dimension+1):\n",
    "                np.save(f\"./features/{encoder}/{data_name}/{k}/{x[i]}_betti{d}.npy\", betti_result[d])\n",
    "                np.save(f\"./features/{encoder}/{data_name}/{k}/{x[i]}_f{d}\", f_result[d])\n",
    "                np.save(f\"./features/{encoder}/{data_name}/{k}/{x[i]}_facet{d}\", facet_result[d])\n",
    "\n",
    "            # -------------------------------\n",
    "            # Save results to .npy files\n",
    "            # -------------------------------\n",
    "            for d in range(max_dimension+2):\n",
    "                np.save(f\"./features/{encoder}/{data_name}/{k}/{x[i]}_h{d}\", h_result[d])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
